{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:53:16.544428Z",
     "iopub.status.busy": "2024-04-26T06:53:16.544043Z",
     "iopub.status.idle": "2024-04-26T06:53:17.738737Z",
     "shell.execute_reply": "2024-04-26T06:53:17.737599Z",
     "shell.execute_reply.started": "2024-04-26T06:53:16.544398Z"
    },
    "id": "si4LbBTu8jOD",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:49.196777Z",
     "start_time": "2024-04-27T03:27:49.144641Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import zipfile as zf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "# Add your libraries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:49.204558Z",
     "start_time": "2024-04-27T03:27:49.198435Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvPLF_vv9a80",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Read in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:59:37.966718Z",
     "iopub.status.busy": "2024-04-26T06:59:37.966352Z",
     "iopub.status.idle": "2024-04-26T06:59:37.973463Z",
     "shell.execute_reply": "2024-04-26T06:59:37.972172Z",
     "shell.execute_reply.started": "2024-04-26T06:59:37.966691Z"
    },
    "id": "5qomZecR_bj9",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:49.206614Z",
     "start_time": "2024-04-27T03:27:49.202020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: /Users/tomkwok/Developer/info911-project/dog-breeds-recognition/testing.csv\n",
      "Train set: /Users/tomkwok/Developer/info911-project/dog-breeds-recognition/training.csv\n"
     ]
    }
   ],
   "source": [
    "# Use the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Kaggle\n",
    "if current_dir == \"/kaggle/working\":\n",
    "    current_dir = \"/kaggle/input/\"\n",
    "\n",
    "\n",
    "file_test_path = f\"{current_dir}/dog-breeds-recognition/testing.csv\"\n",
    "file_train_path = f\"{current_dir}/dog-breeds-recognition/training.csv\"\n",
    "\n",
    "print(f\"Test set: {file_test_path}\")\n",
    "print(f\"Train set: {file_train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:08.094291Z",
     "iopub.status.busy": "2024-04-26T06:54:08.093439Z",
     "iopub.status.idle": "2024-04-26T06:54:09.913098Z",
     "shell.execute_reply": "2024-04-26T06:54:09.910556Z",
     "shell.execute_reply.started": "2024-04-26T06:54:08.094255Z"
    },
    "id": "CUWeskpNABvt",
    "outputId": "11511678-6375-4f0b-d33a-701b938bf77b",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:49.600101Z",
     "start_time": "2024-04-27T03:27:49.207828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any null values in Train: False\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                     0    1         2    \\\n0                 n02085620-Chihuahua\\n02085620_5927.jpg    1  3.508880   \n1                 n02085620-Chihuahua\\n02085620_4441.jpg    1  0.447207   \n2                 n02085620-Chihuahua\\n02085620_1502.jpg    1  1.730776   \n3                 n02085620-Chihuahua\\n02085620_1916.jpg    1  1.986778   \n4                n02085620-Chihuahua\\n02085620_13151.jpg    1  0.000000   \n...                                                  ...  ...       ...   \n11995  n02116738-African_hunting_dog\\n02116738_10614.jpg  120  0.051192   \n11996   n02116738-African_hunting_dog\\n02116738_9282.jpg  120  2.393783   \n11997   n02116738-African_hunting_dog\\n02116738_6754.jpg  120  0.082882   \n11998   n02116738-African_hunting_dog\\n02116738_9333.jpg  120  0.027123   \n11999   n02116738-African_hunting_dog\\n02116738_2503.jpg  120  0.374718   \n\n            3         4         5         6         7         8         9    \\\n0      0.928564  0.298451  0.202423  0.273040  0.073741  0.260721  2.454843   \n1      0.152954  0.214087  1.132086  0.984579  0.352944  0.616292  1.692439   \n2      0.405669  0.187414  0.365856  0.512063  0.772889  0.267891  0.160474   \n3      0.475547  0.114825  0.263515  0.743351  0.053917  0.293086  0.466959   \n4      0.993176  0.362772  0.117868  0.257813  0.817096  0.777969  0.930595   \n...         ...       ...       ...       ...       ...       ...       ...   \n11995  0.263571  1.953465  0.144953  1.881053  1.025135  1.309460  0.026804   \n11996  0.583523  0.070011  2.168356  2.056204  0.418436  0.592864  2.390873   \n11997  0.210209  1.683243  0.442680  2.221987  1.028761  2.321181  0.150616   \n11998  0.675996  0.353758  0.421884  0.610241  0.311903  1.028679  0.632097   \n11999  0.627293  0.173531  0.000000  1.390403  0.759935  2.652178  0.130795   \n\n       ...       504       505       506       507       508       509  \\\n0      ...  0.929986  0.959449  1.033072  0.104633  1.102810  0.058879   \n1      ...  1.842100  0.193077  0.103465  1.228296  2.554505  0.303815   \n2      ...  2.033174  0.272994  0.217314  1.633859  1.064902  0.221387   \n3      ...  1.581877  0.216979  0.313218  2.389633  1.645630  0.348484   \n4      ...  1.301286  0.631204  0.194294  0.170246  2.551018  0.000000   \n...    ...       ...       ...       ...       ...       ...       ...   \n11995  ...  0.804875  0.278833  0.003926  0.465810  0.050890  1.009473   \n11996  ...  0.225061  0.229859  0.935760  0.655962  0.289180  0.623364   \n11997  ...  0.237797  0.049576  0.205640  0.424587  0.558180  0.732412   \n11998  ...  1.706490  0.396890  0.092548  1.995632  0.000000  1.191216   \n11999  ...  0.097647  0.244688  0.047552  0.540931  0.298368  0.637011   \n\n            510       511       512       513  \n0      0.508010  0.386740  0.182575  0.764517  \n1      0.544647  0.715426  0.916348  0.240079  \n2      1.036172  0.591452  0.733662  1.475364  \n3      0.936218  0.733054  0.740681  1.340304  \n4      3.035839  0.058260  1.350222  3.290168  \n...         ...       ...       ...       ...  \n11995  1.667273  1.975637  0.620393  0.057779  \n11996  1.158500  1.949258  1.581664  0.121391  \n11997  1.422601  2.745240  0.044735  0.282376  \n11998  0.196342  0.957877  0.736384  0.034472  \n11999  1.254008  1.859550  0.309276  0.187103  \n\n[12000 rows x 514 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>504</th>\n      <th>505</th>\n      <th>506</th>\n      <th>507</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n      <th>512</th>\n      <th>513</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n02085620-Chihuahua\\n02085620_5927.jpg</td>\n      <td>1</td>\n      <td>3.508880</td>\n      <td>0.928564</td>\n      <td>0.298451</td>\n      <td>0.202423</td>\n      <td>0.273040</td>\n      <td>0.073741</td>\n      <td>0.260721</td>\n      <td>2.454843</td>\n      <td>...</td>\n      <td>0.929986</td>\n      <td>0.959449</td>\n      <td>1.033072</td>\n      <td>0.104633</td>\n      <td>1.102810</td>\n      <td>0.058879</td>\n      <td>0.508010</td>\n      <td>0.386740</td>\n      <td>0.182575</td>\n      <td>0.764517</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n02085620-Chihuahua\\n02085620_4441.jpg</td>\n      <td>1</td>\n      <td>0.447207</td>\n      <td>0.152954</td>\n      <td>0.214087</td>\n      <td>1.132086</td>\n      <td>0.984579</td>\n      <td>0.352944</td>\n      <td>0.616292</td>\n      <td>1.692439</td>\n      <td>...</td>\n      <td>1.842100</td>\n      <td>0.193077</td>\n      <td>0.103465</td>\n      <td>1.228296</td>\n      <td>2.554505</td>\n      <td>0.303815</td>\n      <td>0.544647</td>\n      <td>0.715426</td>\n      <td>0.916348</td>\n      <td>0.240079</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n02085620-Chihuahua\\n02085620_1502.jpg</td>\n      <td>1</td>\n      <td>1.730776</td>\n      <td>0.405669</td>\n      <td>0.187414</td>\n      <td>0.365856</td>\n      <td>0.512063</td>\n      <td>0.772889</td>\n      <td>0.267891</td>\n      <td>0.160474</td>\n      <td>...</td>\n      <td>2.033174</td>\n      <td>0.272994</td>\n      <td>0.217314</td>\n      <td>1.633859</td>\n      <td>1.064902</td>\n      <td>0.221387</td>\n      <td>1.036172</td>\n      <td>0.591452</td>\n      <td>0.733662</td>\n      <td>1.475364</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n02085620-Chihuahua\\n02085620_1916.jpg</td>\n      <td>1</td>\n      <td>1.986778</td>\n      <td>0.475547</td>\n      <td>0.114825</td>\n      <td>0.263515</td>\n      <td>0.743351</td>\n      <td>0.053917</td>\n      <td>0.293086</td>\n      <td>0.466959</td>\n      <td>...</td>\n      <td>1.581877</td>\n      <td>0.216979</td>\n      <td>0.313218</td>\n      <td>2.389633</td>\n      <td>1.645630</td>\n      <td>0.348484</td>\n      <td>0.936218</td>\n      <td>0.733054</td>\n      <td>0.740681</td>\n      <td>1.340304</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n02085620-Chihuahua\\n02085620_13151.jpg</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.993176</td>\n      <td>0.362772</td>\n      <td>0.117868</td>\n      <td>0.257813</td>\n      <td>0.817096</td>\n      <td>0.777969</td>\n      <td>0.930595</td>\n      <td>...</td>\n      <td>1.301286</td>\n      <td>0.631204</td>\n      <td>0.194294</td>\n      <td>0.170246</td>\n      <td>2.551018</td>\n      <td>0.000000</td>\n      <td>3.035839</td>\n      <td>0.058260</td>\n      <td>1.350222</td>\n      <td>3.290168</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11995</th>\n      <td>n02116738-African_hunting_dog\\n02116738_10614.jpg</td>\n      <td>120</td>\n      <td>0.051192</td>\n      <td>0.263571</td>\n      <td>1.953465</td>\n      <td>0.144953</td>\n      <td>1.881053</td>\n      <td>1.025135</td>\n      <td>1.309460</td>\n      <td>0.026804</td>\n      <td>...</td>\n      <td>0.804875</td>\n      <td>0.278833</td>\n      <td>0.003926</td>\n      <td>0.465810</td>\n      <td>0.050890</td>\n      <td>1.009473</td>\n      <td>1.667273</td>\n      <td>1.975637</td>\n      <td>0.620393</td>\n      <td>0.057779</td>\n    </tr>\n    <tr>\n      <th>11996</th>\n      <td>n02116738-African_hunting_dog\\n02116738_9282.jpg</td>\n      <td>120</td>\n      <td>2.393783</td>\n      <td>0.583523</td>\n      <td>0.070011</td>\n      <td>2.168356</td>\n      <td>2.056204</td>\n      <td>0.418436</td>\n      <td>0.592864</td>\n      <td>2.390873</td>\n      <td>...</td>\n      <td>0.225061</td>\n      <td>0.229859</td>\n      <td>0.935760</td>\n      <td>0.655962</td>\n      <td>0.289180</td>\n      <td>0.623364</td>\n      <td>1.158500</td>\n      <td>1.949258</td>\n      <td>1.581664</td>\n      <td>0.121391</td>\n    </tr>\n    <tr>\n      <th>11997</th>\n      <td>n02116738-African_hunting_dog\\n02116738_6754.jpg</td>\n      <td>120</td>\n      <td>0.082882</td>\n      <td>0.210209</td>\n      <td>1.683243</td>\n      <td>0.442680</td>\n      <td>2.221987</td>\n      <td>1.028761</td>\n      <td>2.321181</td>\n      <td>0.150616</td>\n      <td>...</td>\n      <td>0.237797</td>\n      <td>0.049576</td>\n      <td>0.205640</td>\n      <td>0.424587</td>\n      <td>0.558180</td>\n      <td>0.732412</td>\n      <td>1.422601</td>\n      <td>2.745240</td>\n      <td>0.044735</td>\n      <td>0.282376</td>\n    </tr>\n    <tr>\n      <th>11998</th>\n      <td>n02116738-African_hunting_dog\\n02116738_9333.jpg</td>\n      <td>120</td>\n      <td>0.027123</td>\n      <td>0.675996</td>\n      <td>0.353758</td>\n      <td>0.421884</td>\n      <td>0.610241</td>\n      <td>0.311903</td>\n      <td>1.028679</td>\n      <td>0.632097</td>\n      <td>...</td>\n      <td>1.706490</td>\n      <td>0.396890</td>\n      <td>0.092548</td>\n      <td>1.995632</td>\n      <td>0.000000</td>\n      <td>1.191216</td>\n      <td>0.196342</td>\n      <td>0.957877</td>\n      <td>0.736384</td>\n      <td>0.034472</td>\n    </tr>\n    <tr>\n      <th>11999</th>\n      <td>n02116738-African_hunting_dog\\n02116738_2503.jpg</td>\n      <td>120</td>\n      <td>0.374718</td>\n      <td>0.627293</td>\n      <td>0.173531</td>\n      <td>0.000000</td>\n      <td>1.390403</td>\n      <td>0.759935</td>\n      <td>2.652178</td>\n      <td>0.130795</td>\n      <td>...</td>\n      <td>0.097647</td>\n      <td>0.244688</td>\n      <td>0.047552</td>\n      <td>0.540931</td>\n      <td>0.298368</td>\n      <td>0.637011</td>\n      <td>1.254008</td>\n      <td>1.859550</td>\n      <td>0.309276</td>\n      <td>0.187103</td>\n    </tr>\n  </tbody>\n</table>\n<p>12000 rows × 514 columns</p>\n</div>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in train\n",
    "df_train = pd.read_csv(file_train_path, header=None)\n",
    "print(f\"Are there any null values in Train: {df_train.isnull().values.any()}\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:13.189844Z",
     "iopub.status.busy": "2024-04-26T06:54:13.188731Z",
     "iopub.status.idle": "2024-04-26T06:54:14.272470Z",
     "shell.execute_reply": "2024-04-26T06:54:14.271271Z",
     "shell.execute_reply.started": "2024-04-26T06:54:13.189795Z"
    },
    "id": "C8qMYPxwGIt_",
    "outputId": "6fa2346c-f365-4961-e6c9-48f129b23aac",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:49.887252Z",
     "start_time": "2024-04-27T03:27:49.600463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any null values in Test: False\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                   0    1         2    \\\n0               n02085620-Chihuahua\\n02085620_2650.jpg    1  2.750876   \n1               n02085620-Chihuahua\\n02085620_4919.jpg    1  3.723587   \n2               n02085620-Chihuahua\\n02085620_1765.jpg    1  0.971007   \n3               n02085620-Chihuahua\\n02085620_3006.jpg    1  1.874442   \n4               n02085620-Chihuahua\\n02085620_1492.jpg    1  0.254995   \n...                                                ...  ...       ...   \n8575  n02116738-African_hunting_dog\\n02116738_4991.jpg  120  0.068341   \n8576  n02116738-African_hunting_dog\\n02116738_3024.jpg  120  0.012424   \n8577  n02116738-African_hunting_dog\\n02116738_3635.jpg  120  0.090567   \n8578  n02116738-African_hunting_dog\\n02116738_2988.jpg  120  0.249121   \n8579  n02116738-African_hunting_dog\\n02116738_6330.jpg  120  0.006490   \n\n           3         4         5         6         7         8         9    \\\n0     0.402823  0.490048  0.088944  0.067087  0.097192  0.188324  0.554036   \n1     1.346295  0.413855  1.559932  2.922223  0.046513  0.065089  0.748078   \n2     0.447430  0.136485  0.470510  0.371954  0.112476  0.265642  0.300397   \n3     1.340326  0.430788  1.061602  0.018172  0.659020  0.024218  0.541496   \n4     1.975686  0.795596  0.792883  0.491056  1.389314  0.066709  0.368587   \n...        ...       ...       ...       ...       ...       ...       ...   \n8575  0.824908  0.193437  0.906468  2.191380  0.567653  2.182863  0.541500   \n8576  0.074204  1.992666  0.076113  0.573071  1.246892  0.586113  0.114273   \n8577  0.394184  1.207222  0.123069  2.618800  0.823760  3.099759  0.373843   \n8578  0.176359  2.857338  0.408916  0.582186  1.393884  2.366030  0.707135   \n8579  0.197918  0.512689  0.059964  0.486442  0.658949  3.135226  1.372569   \n\n      ...       504       505       506       507       508       509  \\\n0     ...  1.009560  0.560529  0.000568  1.048601  1.888090  0.000000   \n1     ...  0.800828  0.310406  0.141535  0.613455  1.598750  0.285342   \n2     ...  0.944592  1.212590  0.189738  1.528287  2.109546  0.329096   \n3     ...  2.426595  0.921312  0.569086  0.939952  1.300098  1.269613   \n4     ...  1.439100  1.203172  0.787512  0.178735  0.667279  0.644420   \n...   ...       ...       ...       ...       ...       ...       ...   \n8575  ...  0.270837  0.148257  0.538312  0.221652  1.261061  0.393819   \n8576  ...  0.544384  0.052004  0.279680  0.214920  1.575158  1.586292   \n8577  ...  0.082895  0.005232  0.012785  0.310990  0.028843  1.175330   \n8578  ...  0.592481  0.396963  0.142146  0.550736  0.031739  0.102475   \n8579  ...  0.280469  0.263225  0.788225  1.298100  0.071682  0.007359   \n\n           510       511       512       513  \n0     0.072166  0.522479  0.072563  0.040364  \n1     2.139037  1.185468  2.046112  1.761059  \n2     1.496220  1.040246  0.000382  1.097506  \n3     0.131599  0.544578  0.598401  0.251547  \n4     1.120357  1.260047  0.071751  1.355075  \n...        ...       ...       ...       ...  \n8575  0.931265  1.368547  0.725584  1.802775  \n8576  1.686255  0.970767  1.198236  0.281134  \n8577  0.576579  1.986010  0.086537  0.805687  \n8578  2.250938  0.885802  1.031099  0.105213  \n8579  1.349891  2.497369  0.263831  0.009741  \n\n[8580 rows x 514 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>504</th>\n      <th>505</th>\n      <th>506</th>\n      <th>507</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n      <th>512</th>\n      <th>513</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n02085620-Chihuahua\\n02085620_2650.jpg</td>\n      <td>1</td>\n      <td>2.750876</td>\n      <td>0.402823</td>\n      <td>0.490048</td>\n      <td>0.088944</td>\n      <td>0.067087</td>\n      <td>0.097192</td>\n      <td>0.188324</td>\n      <td>0.554036</td>\n      <td>...</td>\n      <td>1.009560</td>\n      <td>0.560529</td>\n      <td>0.000568</td>\n      <td>1.048601</td>\n      <td>1.888090</td>\n      <td>0.000000</td>\n      <td>0.072166</td>\n      <td>0.522479</td>\n      <td>0.072563</td>\n      <td>0.040364</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n02085620-Chihuahua\\n02085620_4919.jpg</td>\n      <td>1</td>\n      <td>3.723587</td>\n      <td>1.346295</td>\n      <td>0.413855</td>\n      <td>1.559932</td>\n      <td>2.922223</td>\n      <td>0.046513</td>\n      <td>0.065089</td>\n      <td>0.748078</td>\n      <td>...</td>\n      <td>0.800828</td>\n      <td>0.310406</td>\n      <td>0.141535</td>\n      <td>0.613455</td>\n      <td>1.598750</td>\n      <td>0.285342</td>\n      <td>2.139037</td>\n      <td>1.185468</td>\n      <td>2.046112</td>\n      <td>1.761059</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n02085620-Chihuahua\\n02085620_1765.jpg</td>\n      <td>1</td>\n      <td>0.971007</td>\n      <td>0.447430</td>\n      <td>0.136485</td>\n      <td>0.470510</td>\n      <td>0.371954</td>\n      <td>0.112476</td>\n      <td>0.265642</td>\n      <td>0.300397</td>\n      <td>...</td>\n      <td>0.944592</td>\n      <td>1.212590</td>\n      <td>0.189738</td>\n      <td>1.528287</td>\n      <td>2.109546</td>\n      <td>0.329096</td>\n      <td>1.496220</td>\n      <td>1.040246</td>\n      <td>0.000382</td>\n      <td>1.097506</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n02085620-Chihuahua\\n02085620_3006.jpg</td>\n      <td>1</td>\n      <td>1.874442</td>\n      <td>1.340326</td>\n      <td>0.430788</td>\n      <td>1.061602</td>\n      <td>0.018172</td>\n      <td>0.659020</td>\n      <td>0.024218</td>\n      <td>0.541496</td>\n      <td>...</td>\n      <td>2.426595</td>\n      <td>0.921312</td>\n      <td>0.569086</td>\n      <td>0.939952</td>\n      <td>1.300098</td>\n      <td>1.269613</td>\n      <td>0.131599</td>\n      <td>0.544578</td>\n      <td>0.598401</td>\n      <td>0.251547</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n02085620-Chihuahua\\n02085620_1492.jpg</td>\n      <td>1</td>\n      <td>0.254995</td>\n      <td>1.975686</td>\n      <td>0.795596</td>\n      <td>0.792883</td>\n      <td>0.491056</td>\n      <td>1.389314</td>\n      <td>0.066709</td>\n      <td>0.368587</td>\n      <td>...</td>\n      <td>1.439100</td>\n      <td>1.203172</td>\n      <td>0.787512</td>\n      <td>0.178735</td>\n      <td>0.667279</td>\n      <td>0.644420</td>\n      <td>1.120357</td>\n      <td>1.260047</td>\n      <td>0.071751</td>\n      <td>1.355075</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8575</th>\n      <td>n02116738-African_hunting_dog\\n02116738_4991.jpg</td>\n      <td>120</td>\n      <td>0.068341</td>\n      <td>0.824908</td>\n      <td>0.193437</td>\n      <td>0.906468</td>\n      <td>2.191380</td>\n      <td>0.567653</td>\n      <td>2.182863</td>\n      <td>0.541500</td>\n      <td>...</td>\n      <td>0.270837</td>\n      <td>0.148257</td>\n      <td>0.538312</td>\n      <td>0.221652</td>\n      <td>1.261061</td>\n      <td>0.393819</td>\n      <td>0.931265</td>\n      <td>1.368547</td>\n      <td>0.725584</td>\n      <td>1.802775</td>\n    </tr>\n    <tr>\n      <th>8576</th>\n      <td>n02116738-African_hunting_dog\\n02116738_3024.jpg</td>\n      <td>120</td>\n      <td>0.012424</td>\n      <td>0.074204</td>\n      <td>1.992666</td>\n      <td>0.076113</td>\n      <td>0.573071</td>\n      <td>1.246892</td>\n      <td>0.586113</td>\n      <td>0.114273</td>\n      <td>...</td>\n      <td>0.544384</td>\n      <td>0.052004</td>\n      <td>0.279680</td>\n      <td>0.214920</td>\n      <td>1.575158</td>\n      <td>1.586292</td>\n      <td>1.686255</td>\n      <td>0.970767</td>\n      <td>1.198236</td>\n      <td>0.281134</td>\n    </tr>\n    <tr>\n      <th>8577</th>\n      <td>n02116738-African_hunting_dog\\n02116738_3635.jpg</td>\n      <td>120</td>\n      <td>0.090567</td>\n      <td>0.394184</td>\n      <td>1.207222</td>\n      <td>0.123069</td>\n      <td>2.618800</td>\n      <td>0.823760</td>\n      <td>3.099759</td>\n      <td>0.373843</td>\n      <td>...</td>\n      <td>0.082895</td>\n      <td>0.005232</td>\n      <td>0.012785</td>\n      <td>0.310990</td>\n      <td>0.028843</td>\n      <td>1.175330</td>\n      <td>0.576579</td>\n      <td>1.986010</td>\n      <td>0.086537</td>\n      <td>0.805687</td>\n    </tr>\n    <tr>\n      <th>8578</th>\n      <td>n02116738-African_hunting_dog\\n02116738_2988.jpg</td>\n      <td>120</td>\n      <td>0.249121</td>\n      <td>0.176359</td>\n      <td>2.857338</td>\n      <td>0.408916</td>\n      <td>0.582186</td>\n      <td>1.393884</td>\n      <td>2.366030</td>\n      <td>0.707135</td>\n      <td>...</td>\n      <td>0.592481</td>\n      <td>0.396963</td>\n      <td>0.142146</td>\n      <td>0.550736</td>\n      <td>0.031739</td>\n      <td>0.102475</td>\n      <td>2.250938</td>\n      <td>0.885802</td>\n      <td>1.031099</td>\n      <td>0.105213</td>\n    </tr>\n    <tr>\n      <th>8579</th>\n      <td>n02116738-African_hunting_dog\\n02116738_6330.jpg</td>\n      <td>120</td>\n      <td>0.006490</td>\n      <td>0.197918</td>\n      <td>0.512689</td>\n      <td>0.059964</td>\n      <td>0.486442</td>\n      <td>0.658949</td>\n      <td>3.135226</td>\n      <td>1.372569</td>\n      <td>...</td>\n      <td>0.280469</td>\n      <td>0.263225</td>\n      <td>0.788225</td>\n      <td>1.298100</td>\n      <td>0.071682</td>\n      <td>0.007359</td>\n      <td>1.349891</td>\n      <td>2.497369</td>\n      <td>0.263831</td>\n      <td>0.009741</td>\n    </tr>\n  </tbody>\n</table>\n<p>8580 rows × 514 columns</p>\n</div>"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in test\n",
    "df_test = pd.read_csv(file_test_path, header=None)\n",
    "print(f\"Are there any null values in Test: {df_test.isnull().values.any()}\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIoaCRVvqPio",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Reformat Dataframe**\n",
    "* The dataset doesn't come with column names, lets add some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:22.178790Z",
     "iopub.status.busy": "2024-04-26T06:54:22.178420Z",
     "iopub.status.idle": "2024-04-26T06:54:22.184755Z",
     "shell.execute_reply": "2024-04-26T06:54:22.183416Z",
     "shell.execute_reply.started": "2024-04-26T06:54:22.178762Z"
    },
    "id": "BlyR3800qbJh",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:49.891291Z",
     "start_time": "2024-04-27T03:27:49.887316Z"
    }
   },
   "outputs": [],
   "source": [
    "def reformat_df(df):\n",
    "  df = df.rename(columns={0:\"image_path\", 1:\"target\"})\n",
    "  for header in df.columns[2:]:\n",
    "    new_header = f\"feature_{header-1}\"\n",
    "    df.rename(columns={header:new_header}, inplace=True)\n",
    "  df = df.set_index(\"image_path\")\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:25.182156Z",
     "iopub.status.busy": "2024-04-26T06:54:25.181290Z",
     "iopub.status.idle": "2024-04-26T06:54:25.527456Z",
     "shell.execute_reply": "2024-04-26T06:54:25.526329Z",
     "shell.execute_reply.started": "2024-04-26T06:54:25.182085Z"
    },
    "id": "VPh9BY5JqpEp",
    "outputId": "c8ab3768-f51b-4835-9aef-f21596279997",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:49.992624Z",
     "start_time": "2024-04-27T03:27:49.890584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   target  feature_1  \\\nimage_path                                                             \nn02085620-Chihuahua\\n02085620_5927.jpg                  1   3.508880   \nn02085620-Chihuahua\\n02085620_4441.jpg                  1   0.447207   \nn02085620-Chihuahua\\n02085620_1502.jpg                  1   1.730776   \nn02085620-Chihuahua\\n02085620_1916.jpg                  1   1.986778   \nn02085620-Chihuahua\\n02085620_13151.jpg                 1   0.000000   \n...                                                   ...        ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg     120   0.051192   \nn02116738-African_hunting_dog\\n02116738_9282.jpg      120   2.393783   \nn02116738-African_hunting_dog\\n02116738_6754.jpg      120   0.082882   \nn02116738-African_hunting_dog\\n02116738_9333.jpg      120   0.027123   \nn02116738-African_hunting_dog\\n02116738_2503.jpg      120   0.374718   \n\n                                                   feature_2  feature_3  \\\nimage_path                                                                \nn02085620-Chihuahua\\n02085620_5927.jpg              0.928564   0.298451   \nn02085620-Chihuahua\\n02085620_4441.jpg              0.152954   0.214087   \nn02085620-Chihuahua\\n02085620_1502.jpg              0.405669   0.187414   \nn02085620-Chihuahua\\n02085620_1916.jpg              0.475547   0.114825   \nn02085620-Chihuahua\\n02085620_13151.jpg             0.993176   0.362772   \n...                                                      ...        ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg   0.263571   1.953465   \nn02116738-African_hunting_dog\\n02116738_9282.jpg    0.583523   0.070011   \nn02116738-African_hunting_dog\\n02116738_6754.jpg    0.210209   1.683243   \nn02116738-African_hunting_dog\\n02116738_9333.jpg    0.675996   0.353758   \nn02116738-African_hunting_dog\\n02116738_2503.jpg    0.627293   0.173531   \n\n                                                   feature_4  feature_5  \\\nimage_path                                                                \nn02085620-Chihuahua\\n02085620_5927.jpg              0.202423   0.273040   \nn02085620-Chihuahua\\n02085620_4441.jpg              1.132086   0.984579   \nn02085620-Chihuahua\\n02085620_1502.jpg              0.365856   0.512063   \nn02085620-Chihuahua\\n02085620_1916.jpg              0.263515   0.743351   \nn02085620-Chihuahua\\n02085620_13151.jpg             0.117868   0.257813   \n...                                                      ...        ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg   0.144953   1.881053   \nn02116738-African_hunting_dog\\n02116738_9282.jpg    2.168356   2.056204   \nn02116738-African_hunting_dog\\n02116738_6754.jpg    0.442680   2.221987   \nn02116738-African_hunting_dog\\n02116738_9333.jpg    0.421884   0.610241   \nn02116738-African_hunting_dog\\n02116738_2503.jpg    0.000000   1.390403   \n\n                                                   feature_6  feature_7  \\\nimage_path                                                                \nn02085620-Chihuahua\\n02085620_5927.jpg              0.073741   0.260721   \nn02085620-Chihuahua\\n02085620_4441.jpg              0.352944   0.616292   \nn02085620-Chihuahua\\n02085620_1502.jpg              0.772889   0.267891   \nn02085620-Chihuahua\\n02085620_1916.jpg              0.053917   0.293086   \nn02085620-Chihuahua\\n02085620_13151.jpg             0.817096   0.777969   \n...                                                      ...        ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg   1.025135   1.309460   \nn02116738-African_hunting_dog\\n02116738_9282.jpg    0.418436   0.592864   \nn02116738-African_hunting_dog\\n02116738_6754.jpg    1.028761   2.321181   \nn02116738-African_hunting_dog\\n02116738_9333.jpg    0.311903   1.028679   \nn02116738-African_hunting_dog\\n02116738_2503.jpg    0.759935   2.652178   \n\n                                                   feature_8  feature_9  ...  \\\nimage_path                                                               ...   \nn02085620-Chihuahua\\n02085620_5927.jpg              2.454843   0.677149  ...   \nn02085620-Chihuahua\\n02085620_4441.jpg              1.692439   1.767242  ...   \nn02085620-Chihuahua\\n02085620_1502.jpg              0.160474   1.124645  ...   \nn02085620-Chihuahua\\n02085620_1916.jpg              0.466959   0.154945  ...   \nn02085620-Chihuahua\\n02085620_13151.jpg             0.930595   1.155066  ...   \n...                                                      ...        ...  ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg   0.026804   1.145573  ...   \nn02116738-African_hunting_dog\\n02116738_9282.jpg    2.390873   0.191504  ...   \nn02116738-African_hunting_dog\\n02116738_6754.jpg    0.150616   1.760209  ...   \nn02116738-African_hunting_dog\\n02116738_9333.jpg    0.632097   0.693826  ...   \nn02116738-African_hunting_dog\\n02116738_2503.jpg    0.130795   0.481706  ...   \n\n                                                   feature_503  feature_504  \\\nimage_path                                                                    \nn02085620-Chihuahua\\n02085620_5927.jpg                0.929986     0.959449   \nn02085620-Chihuahua\\n02085620_4441.jpg                1.842100     0.193077   \nn02085620-Chihuahua\\n02085620_1502.jpg                2.033174     0.272994   \nn02085620-Chihuahua\\n02085620_1916.jpg                1.581877     0.216979   \nn02085620-Chihuahua\\n02085620_13151.jpg               1.301286     0.631204   \n...                                                        ...          ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg     0.804875     0.278833   \nn02116738-African_hunting_dog\\n02116738_9282.jpg      0.225061     0.229859   \nn02116738-African_hunting_dog\\n02116738_6754.jpg      0.237797     0.049576   \nn02116738-African_hunting_dog\\n02116738_9333.jpg      1.706490     0.396890   \nn02116738-African_hunting_dog\\n02116738_2503.jpg      0.097647     0.244688   \n\n                                                   feature_505  feature_506  \\\nimage_path                                                                    \nn02085620-Chihuahua\\n02085620_5927.jpg                1.033072     0.104633   \nn02085620-Chihuahua\\n02085620_4441.jpg                0.103465     1.228296   \nn02085620-Chihuahua\\n02085620_1502.jpg                0.217314     1.633859   \nn02085620-Chihuahua\\n02085620_1916.jpg                0.313218     2.389633   \nn02085620-Chihuahua\\n02085620_13151.jpg               0.194294     0.170246   \n...                                                        ...          ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg     0.003926     0.465810   \nn02116738-African_hunting_dog\\n02116738_9282.jpg      0.935760     0.655962   \nn02116738-African_hunting_dog\\n02116738_6754.jpg      0.205640     0.424587   \nn02116738-African_hunting_dog\\n02116738_9333.jpg      0.092548     1.995632   \nn02116738-African_hunting_dog\\n02116738_2503.jpg      0.047552     0.540931   \n\n                                                   feature_507  feature_508  \\\nimage_path                                                                    \nn02085620-Chihuahua\\n02085620_5927.jpg                1.102810     0.058879   \nn02085620-Chihuahua\\n02085620_4441.jpg                2.554505     0.303815   \nn02085620-Chihuahua\\n02085620_1502.jpg                1.064902     0.221387   \nn02085620-Chihuahua\\n02085620_1916.jpg                1.645630     0.348484   \nn02085620-Chihuahua\\n02085620_13151.jpg               2.551018     0.000000   \n...                                                        ...          ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg     0.050890     1.009473   \nn02116738-African_hunting_dog\\n02116738_9282.jpg      0.289180     0.623364   \nn02116738-African_hunting_dog\\n02116738_6754.jpg      0.558180     0.732412   \nn02116738-African_hunting_dog\\n02116738_9333.jpg      0.000000     1.191216   \nn02116738-African_hunting_dog\\n02116738_2503.jpg      0.298368     0.637011   \n\n                                                   feature_509  feature_510  \\\nimage_path                                                                    \nn02085620-Chihuahua\\n02085620_5927.jpg                0.508010     0.386740   \nn02085620-Chihuahua\\n02085620_4441.jpg                0.544647     0.715426   \nn02085620-Chihuahua\\n02085620_1502.jpg                1.036172     0.591452   \nn02085620-Chihuahua\\n02085620_1916.jpg                0.936218     0.733054   \nn02085620-Chihuahua\\n02085620_13151.jpg               3.035839     0.058260   \n...                                                        ...          ...   \nn02116738-African_hunting_dog\\n02116738_10614.jpg     1.667273     1.975637   \nn02116738-African_hunting_dog\\n02116738_9282.jpg      1.158500     1.949258   \nn02116738-African_hunting_dog\\n02116738_6754.jpg      1.422601     2.745240   \nn02116738-African_hunting_dog\\n02116738_9333.jpg      0.196342     0.957877   \nn02116738-African_hunting_dog\\n02116738_2503.jpg      1.254008     1.859550   \n\n                                                   feature_511  feature_512  \nimage_path                                                                   \nn02085620-Chihuahua\\n02085620_5927.jpg                0.182575     0.764517  \nn02085620-Chihuahua\\n02085620_4441.jpg                0.916348     0.240079  \nn02085620-Chihuahua\\n02085620_1502.jpg                0.733662     1.475364  \nn02085620-Chihuahua\\n02085620_1916.jpg                0.740681     1.340304  \nn02085620-Chihuahua\\n02085620_13151.jpg               1.350222     3.290168  \n...                                                        ...          ...  \nn02116738-African_hunting_dog\\n02116738_10614.jpg     0.620393     0.057779  \nn02116738-African_hunting_dog\\n02116738_9282.jpg      1.581664     0.121391  \nn02116738-African_hunting_dog\\n02116738_6754.jpg      0.044735     0.282376  \nn02116738-African_hunting_dog\\n02116738_9333.jpg      0.736384     0.034472  \nn02116738-African_hunting_dog\\n02116738_2503.jpg      0.309276     0.187103  \n\n[12000 rows x 513 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>...</th>\n      <th>feature_503</th>\n      <th>feature_504</th>\n      <th>feature_505</th>\n      <th>feature_506</th>\n      <th>feature_507</th>\n      <th>feature_508</th>\n      <th>feature_509</th>\n      <th>feature_510</th>\n      <th>feature_511</th>\n      <th>feature_512</th>\n    </tr>\n    <tr>\n      <th>image_path</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_5927.jpg</th>\n      <td>1</td>\n      <td>3.508880</td>\n      <td>0.928564</td>\n      <td>0.298451</td>\n      <td>0.202423</td>\n      <td>0.273040</td>\n      <td>0.073741</td>\n      <td>0.260721</td>\n      <td>2.454843</td>\n      <td>0.677149</td>\n      <td>...</td>\n      <td>0.929986</td>\n      <td>0.959449</td>\n      <td>1.033072</td>\n      <td>0.104633</td>\n      <td>1.102810</td>\n      <td>0.058879</td>\n      <td>0.508010</td>\n      <td>0.386740</td>\n      <td>0.182575</td>\n      <td>0.764517</td>\n    </tr>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_4441.jpg</th>\n      <td>1</td>\n      <td>0.447207</td>\n      <td>0.152954</td>\n      <td>0.214087</td>\n      <td>1.132086</td>\n      <td>0.984579</td>\n      <td>0.352944</td>\n      <td>0.616292</td>\n      <td>1.692439</td>\n      <td>1.767242</td>\n      <td>...</td>\n      <td>1.842100</td>\n      <td>0.193077</td>\n      <td>0.103465</td>\n      <td>1.228296</td>\n      <td>2.554505</td>\n      <td>0.303815</td>\n      <td>0.544647</td>\n      <td>0.715426</td>\n      <td>0.916348</td>\n      <td>0.240079</td>\n    </tr>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_1502.jpg</th>\n      <td>1</td>\n      <td>1.730776</td>\n      <td>0.405669</td>\n      <td>0.187414</td>\n      <td>0.365856</td>\n      <td>0.512063</td>\n      <td>0.772889</td>\n      <td>0.267891</td>\n      <td>0.160474</td>\n      <td>1.124645</td>\n      <td>...</td>\n      <td>2.033174</td>\n      <td>0.272994</td>\n      <td>0.217314</td>\n      <td>1.633859</td>\n      <td>1.064902</td>\n      <td>0.221387</td>\n      <td>1.036172</td>\n      <td>0.591452</td>\n      <td>0.733662</td>\n      <td>1.475364</td>\n    </tr>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_1916.jpg</th>\n      <td>1</td>\n      <td>1.986778</td>\n      <td>0.475547</td>\n      <td>0.114825</td>\n      <td>0.263515</td>\n      <td>0.743351</td>\n      <td>0.053917</td>\n      <td>0.293086</td>\n      <td>0.466959</td>\n      <td>0.154945</td>\n      <td>...</td>\n      <td>1.581877</td>\n      <td>0.216979</td>\n      <td>0.313218</td>\n      <td>2.389633</td>\n      <td>1.645630</td>\n      <td>0.348484</td>\n      <td>0.936218</td>\n      <td>0.733054</td>\n      <td>0.740681</td>\n      <td>1.340304</td>\n    </tr>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_13151.jpg</th>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.993176</td>\n      <td>0.362772</td>\n      <td>0.117868</td>\n      <td>0.257813</td>\n      <td>0.817096</td>\n      <td>0.777969</td>\n      <td>0.930595</td>\n      <td>1.155066</td>\n      <td>...</td>\n      <td>1.301286</td>\n      <td>0.631204</td>\n      <td>0.194294</td>\n      <td>0.170246</td>\n      <td>2.551018</td>\n      <td>0.000000</td>\n      <td>3.035839</td>\n      <td>0.058260</td>\n      <td>1.350222</td>\n      <td>3.290168</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_10614.jpg</th>\n      <td>120</td>\n      <td>0.051192</td>\n      <td>0.263571</td>\n      <td>1.953465</td>\n      <td>0.144953</td>\n      <td>1.881053</td>\n      <td>1.025135</td>\n      <td>1.309460</td>\n      <td>0.026804</td>\n      <td>1.145573</td>\n      <td>...</td>\n      <td>0.804875</td>\n      <td>0.278833</td>\n      <td>0.003926</td>\n      <td>0.465810</td>\n      <td>0.050890</td>\n      <td>1.009473</td>\n      <td>1.667273</td>\n      <td>1.975637</td>\n      <td>0.620393</td>\n      <td>0.057779</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_9282.jpg</th>\n      <td>120</td>\n      <td>2.393783</td>\n      <td>0.583523</td>\n      <td>0.070011</td>\n      <td>2.168356</td>\n      <td>2.056204</td>\n      <td>0.418436</td>\n      <td>0.592864</td>\n      <td>2.390873</td>\n      <td>0.191504</td>\n      <td>...</td>\n      <td>0.225061</td>\n      <td>0.229859</td>\n      <td>0.935760</td>\n      <td>0.655962</td>\n      <td>0.289180</td>\n      <td>0.623364</td>\n      <td>1.158500</td>\n      <td>1.949258</td>\n      <td>1.581664</td>\n      <td>0.121391</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_6754.jpg</th>\n      <td>120</td>\n      <td>0.082882</td>\n      <td>0.210209</td>\n      <td>1.683243</td>\n      <td>0.442680</td>\n      <td>2.221987</td>\n      <td>1.028761</td>\n      <td>2.321181</td>\n      <td>0.150616</td>\n      <td>1.760209</td>\n      <td>...</td>\n      <td>0.237797</td>\n      <td>0.049576</td>\n      <td>0.205640</td>\n      <td>0.424587</td>\n      <td>0.558180</td>\n      <td>0.732412</td>\n      <td>1.422601</td>\n      <td>2.745240</td>\n      <td>0.044735</td>\n      <td>0.282376</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_9333.jpg</th>\n      <td>120</td>\n      <td>0.027123</td>\n      <td>0.675996</td>\n      <td>0.353758</td>\n      <td>0.421884</td>\n      <td>0.610241</td>\n      <td>0.311903</td>\n      <td>1.028679</td>\n      <td>0.632097</td>\n      <td>0.693826</td>\n      <td>...</td>\n      <td>1.706490</td>\n      <td>0.396890</td>\n      <td>0.092548</td>\n      <td>1.995632</td>\n      <td>0.000000</td>\n      <td>1.191216</td>\n      <td>0.196342</td>\n      <td>0.957877</td>\n      <td>0.736384</td>\n      <td>0.034472</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_2503.jpg</th>\n      <td>120</td>\n      <td>0.374718</td>\n      <td>0.627293</td>\n      <td>0.173531</td>\n      <td>0.000000</td>\n      <td>1.390403</td>\n      <td>0.759935</td>\n      <td>2.652178</td>\n      <td>0.130795</td>\n      <td>0.481706</td>\n      <td>...</td>\n      <td>0.097647</td>\n      <td>0.244688</td>\n      <td>0.047552</td>\n      <td>0.540931</td>\n      <td>0.298368</td>\n      <td>0.637011</td>\n      <td>1.254008</td>\n      <td>1.859550</td>\n      <td>0.309276</td>\n      <td>0.187103</td>\n    </tr>\n  </tbody>\n</table>\n<p>12000 rows × 513 columns</p>\n</div>"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = reformat_df(df_train)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:31.495384Z",
     "iopub.status.busy": "2024-04-26T06:54:31.493992Z",
     "iopub.status.idle": "2024-04-26T06:54:31.816039Z",
     "shell.execute_reply": "2024-04-26T06:54:31.814928Z",
     "shell.execute_reply.started": "2024-04-26T06:54:31.495327Z"
    },
    "id": "gPQIeuJ2qybv",
    "outputId": "41a0becd-9f75-4ea9-8718-e46401a8923f",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:50.088768Z",
     "start_time": "2024-04-27T03:27:49.989676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  target  feature_1  \\\nimage_path                                                            \nn02085620-Chihuahua\\n02085620_2650.jpg                 1   2.750876   \nn02085620-Chihuahua\\n02085620_4919.jpg                 1   3.723587   \nn02085620-Chihuahua\\n02085620_1765.jpg                 1   0.971007   \nn02085620-Chihuahua\\n02085620_3006.jpg                 1   1.874442   \nn02085620-Chihuahua\\n02085620_1492.jpg                 1   0.254995   \n...                                                  ...        ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg     120   0.068341   \nn02116738-African_hunting_dog\\n02116738_3024.jpg     120   0.012424   \nn02116738-African_hunting_dog\\n02116738_3635.jpg     120   0.090567   \nn02116738-African_hunting_dog\\n02116738_2988.jpg     120   0.249121   \nn02116738-African_hunting_dog\\n02116738_6330.jpg     120   0.006490   \n\n                                                  feature_2  feature_3  \\\nimage_path                                                               \nn02085620-Chihuahua\\n02085620_2650.jpg             0.402823   0.490048   \nn02085620-Chihuahua\\n02085620_4919.jpg             1.346295   0.413855   \nn02085620-Chihuahua\\n02085620_1765.jpg             0.447430   0.136485   \nn02085620-Chihuahua\\n02085620_3006.jpg             1.340326   0.430788   \nn02085620-Chihuahua\\n02085620_1492.jpg             1.975686   0.795596   \n...                                                     ...        ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg   0.824908   0.193437   \nn02116738-African_hunting_dog\\n02116738_3024.jpg   0.074204   1.992666   \nn02116738-African_hunting_dog\\n02116738_3635.jpg   0.394184   1.207222   \nn02116738-African_hunting_dog\\n02116738_2988.jpg   0.176359   2.857338   \nn02116738-African_hunting_dog\\n02116738_6330.jpg   0.197918   0.512689   \n\n                                                  feature_4  feature_5  \\\nimage_path                                                               \nn02085620-Chihuahua\\n02085620_2650.jpg             0.088944   0.067087   \nn02085620-Chihuahua\\n02085620_4919.jpg             1.559932   2.922223   \nn02085620-Chihuahua\\n02085620_1765.jpg             0.470510   0.371954   \nn02085620-Chihuahua\\n02085620_3006.jpg             1.061602   0.018172   \nn02085620-Chihuahua\\n02085620_1492.jpg             0.792883   0.491056   \n...                                                     ...        ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg   0.906468   2.191380   \nn02116738-African_hunting_dog\\n02116738_3024.jpg   0.076113   0.573071   \nn02116738-African_hunting_dog\\n02116738_3635.jpg   0.123069   2.618800   \nn02116738-African_hunting_dog\\n02116738_2988.jpg   0.408916   0.582186   \nn02116738-African_hunting_dog\\n02116738_6330.jpg   0.059964   0.486442   \n\n                                                  feature_6  feature_7  \\\nimage_path                                                               \nn02085620-Chihuahua\\n02085620_2650.jpg             0.097192   0.188324   \nn02085620-Chihuahua\\n02085620_4919.jpg             0.046513   0.065089   \nn02085620-Chihuahua\\n02085620_1765.jpg             0.112476   0.265642   \nn02085620-Chihuahua\\n02085620_3006.jpg             0.659020   0.024218   \nn02085620-Chihuahua\\n02085620_1492.jpg             1.389314   0.066709   \n...                                                     ...        ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg   0.567653   2.182863   \nn02116738-African_hunting_dog\\n02116738_3024.jpg   1.246892   0.586113   \nn02116738-African_hunting_dog\\n02116738_3635.jpg   0.823760   3.099759   \nn02116738-African_hunting_dog\\n02116738_2988.jpg   1.393884   2.366030   \nn02116738-African_hunting_dog\\n02116738_6330.jpg   0.658949   3.135226   \n\n                                                  feature_8  feature_9  ...  \\\nimage_path                                                              ...   \nn02085620-Chihuahua\\n02085620_2650.jpg             0.554036   0.597607  ...   \nn02085620-Chihuahua\\n02085620_4919.jpg             0.748078   1.062587  ...   \nn02085620-Chihuahua\\n02085620_1765.jpg             0.300397   1.756382  ...   \nn02085620-Chihuahua\\n02085620_3006.jpg             0.541496   0.913266  ...   \nn02085620-Chihuahua\\n02085620_1492.jpg             0.368587   1.323611  ...   \n...                                                     ...        ...  ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg   0.541500   0.469749  ...   \nn02116738-African_hunting_dog\\n02116738_3024.jpg   0.114273   1.963169  ...   \nn02116738-African_hunting_dog\\n02116738_3635.jpg   0.373843   0.408895  ...   \nn02116738-African_hunting_dog\\n02116738_2988.jpg   0.707135   0.630027  ...   \nn02116738-African_hunting_dog\\n02116738_6330.jpg   1.372569   0.247659  ...   \n\n                                                  feature_503  feature_504  \\\nimage_path                                                                   \nn02085620-Chihuahua\\n02085620_2650.jpg               1.009560     0.560529   \nn02085620-Chihuahua\\n02085620_4919.jpg               0.800828     0.310406   \nn02085620-Chihuahua\\n02085620_1765.jpg               0.944592     1.212590   \nn02085620-Chihuahua\\n02085620_3006.jpg               2.426595     0.921312   \nn02085620-Chihuahua\\n02085620_1492.jpg               1.439100     1.203172   \n...                                                       ...          ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg     0.270837     0.148257   \nn02116738-African_hunting_dog\\n02116738_3024.jpg     0.544384     0.052004   \nn02116738-African_hunting_dog\\n02116738_3635.jpg     0.082895     0.005232   \nn02116738-African_hunting_dog\\n02116738_2988.jpg     0.592481     0.396963   \nn02116738-African_hunting_dog\\n02116738_6330.jpg     0.280469     0.263225   \n\n                                                  feature_505  feature_506  \\\nimage_path                                                                   \nn02085620-Chihuahua\\n02085620_2650.jpg               0.000568     1.048601   \nn02085620-Chihuahua\\n02085620_4919.jpg               0.141535     0.613455   \nn02085620-Chihuahua\\n02085620_1765.jpg               0.189738     1.528287   \nn02085620-Chihuahua\\n02085620_3006.jpg               0.569086     0.939952   \nn02085620-Chihuahua\\n02085620_1492.jpg               0.787512     0.178735   \n...                                                       ...          ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg     0.538312     0.221652   \nn02116738-African_hunting_dog\\n02116738_3024.jpg     0.279680     0.214920   \nn02116738-African_hunting_dog\\n02116738_3635.jpg     0.012785     0.310990   \nn02116738-African_hunting_dog\\n02116738_2988.jpg     0.142146     0.550736   \nn02116738-African_hunting_dog\\n02116738_6330.jpg     0.788225     1.298100   \n\n                                                  feature_507  feature_508  \\\nimage_path                                                                   \nn02085620-Chihuahua\\n02085620_2650.jpg               1.888090     0.000000   \nn02085620-Chihuahua\\n02085620_4919.jpg               1.598750     0.285342   \nn02085620-Chihuahua\\n02085620_1765.jpg               2.109546     0.329096   \nn02085620-Chihuahua\\n02085620_3006.jpg               1.300098     1.269613   \nn02085620-Chihuahua\\n02085620_1492.jpg               0.667279     0.644420   \n...                                                       ...          ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg     1.261061     0.393819   \nn02116738-African_hunting_dog\\n02116738_3024.jpg     1.575158     1.586292   \nn02116738-African_hunting_dog\\n02116738_3635.jpg     0.028843     1.175330   \nn02116738-African_hunting_dog\\n02116738_2988.jpg     0.031739     0.102475   \nn02116738-African_hunting_dog\\n02116738_6330.jpg     0.071682     0.007359   \n\n                                                  feature_509  feature_510  \\\nimage_path                                                                   \nn02085620-Chihuahua\\n02085620_2650.jpg               0.072166     0.522479   \nn02085620-Chihuahua\\n02085620_4919.jpg               2.139037     1.185468   \nn02085620-Chihuahua\\n02085620_1765.jpg               1.496220     1.040246   \nn02085620-Chihuahua\\n02085620_3006.jpg               0.131599     0.544578   \nn02085620-Chihuahua\\n02085620_1492.jpg               1.120357     1.260047   \n...                                                       ...          ...   \nn02116738-African_hunting_dog\\n02116738_4991.jpg     0.931265     1.368547   \nn02116738-African_hunting_dog\\n02116738_3024.jpg     1.686255     0.970767   \nn02116738-African_hunting_dog\\n02116738_3635.jpg     0.576579     1.986010   \nn02116738-African_hunting_dog\\n02116738_2988.jpg     2.250938     0.885802   \nn02116738-African_hunting_dog\\n02116738_6330.jpg     1.349891     2.497369   \n\n                                                  feature_511  feature_512  \nimage_path                                                                  \nn02085620-Chihuahua\\n02085620_2650.jpg               0.072563     0.040364  \nn02085620-Chihuahua\\n02085620_4919.jpg               2.046112     1.761059  \nn02085620-Chihuahua\\n02085620_1765.jpg               0.000382     1.097506  \nn02085620-Chihuahua\\n02085620_3006.jpg               0.598401     0.251547  \nn02085620-Chihuahua\\n02085620_1492.jpg               0.071751     1.355075  \n...                                                       ...          ...  \nn02116738-African_hunting_dog\\n02116738_4991.jpg     0.725584     1.802775  \nn02116738-African_hunting_dog\\n02116738_3024.jpg     1.198236     0.281134  \nn02116738-African_hunting_dog\\n02116738_3635.jpg     0.086537     0.805687  \nn02116738-African_hunting_dog\\n02116738_2988.jpg     1.031099     0.105213  \nn02116738-African_hunting_dog\\n02116738_6330.jpg     0.263831     0.009741  \n\n[8580 rows x 513 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>...</th>\n      <th>feature_503</th>\n      <th>feature_504</th>\n      <th>feature_505</th>\n      <th>feature_506</th>\n      <th>feature_507</th>\n      <th>feature_508</th>\n      <th>feature_509</th>\n      <th>feature_510</th>\n      <th>feature_511</th>\n      <th>feature_512</th>\n    </tr>\n    <tr>\n      <th>image_path</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_2650.jpg</th>\n      <td>1</td>\n      <td>2.750876</td>\n      <td>0.402823</td>\n      <td>0.490048</td>\n      <td>0.088944</td>\n      <td>0.067087</td>\n      <td>0.097192</td>\n      <td>0.188324</td>\n      <td>0.554036</td>\n      <td>0.597607</td>\n      <td>...</td>\n      <td>1.009560</td>\n      <td>0.560529</td>\n      <td>0.000568</td>\n      <td>1.048601</td>\n      <td>1.888090</td>\n      <td>0.000000</td>\n      <td>0.072166</td>\n      <td>0.522479</td>\n      <td>0.072563</td>\n      <td>0.040364</td>\n    </tr>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_4919.jpg</th>\n      <td>1</td>\n      <td>3.723587</td>\n      <td>1.346295</td>\n      <td>0.413855</td>\n      <td>1.559932</td>\n      <td>2.922223</td>\n      <td>0.046513</td>\n      <td>0.065089</td>\n      <td>0.748078</td>\n      <td>1.062587</td>\n      <td>...</td>\n      <td>0.800828</td>\n      <td>0.310406</td>\n      <td>0.141535</td>\n      <td>0.613455</td>\n      <td>1.598750</td>\n      <td>0.285342</td>\n      <td>2.139037</td>\n      <td>1.185468</td>\n      <td>2.046112</td>\n      <td>1.761059</td>\n    </tr>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_1765.jpg</th>\n      <td>1</td>\n      <td>0.971007</td>\n      <td>0.447430</td>\n      <td>0.136485</td>\n      <td>0.470510</td>\n      <td>0.371954</td>\n      <td>0.112476</td>\n      <td>0.265642</td>\n      <td>0.300397</td>\n      <td>1.756382</td>\n      <td>...</td>\n      <td>0.944592</td>\n      <td>1.212590</td>\n      <td>0.189738</td>\n      <td>1.528287</td>\n      <td>2.109546</td>\n      <td>0.329096</td>\n      <td>1.496220</td>\n      <td>1.040246</td>\n      <td>0.000382</td>\n      <td>1.097506</td>\n    </tr>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_3006.jpg</th>\n      <td>1</td>\n      <td>1.874442</td>\n      <td>1.340326</td>\n      <td>0.430788</td>\n      <td>1.061602</td>\n      <td>0.018172</td>\n      <td>0.659020</td>\n      <td>0.024218</td>\n      <td>0.541496</td>\n      <td>0.913266</td>\n      <td>...</td>\n      <td>2.426595</td>\n      <td>0.921312</td>\n      <td>0.569086</td>\n      <td>0.939952</td>\n      <td>1.300098</td>\n      <td>1.269613</td>\n      <td>0.131599</td>\n      <td>0.544578</td>\n      <td>0.598401</td>\n      <td>0.251547</td>\n    </tr>\n    <tr>\n      <th>n02085620-Chihuahua\\n02085620_1492.jpg</th>\n      <td>1</td>\n      <td>0.254995</td>\n      <td>1.975686</td>\n      <td>0.795596</td>\n      <td>0.792883</td>\n      <td>0.491056</td>\n      <td>1.389314</td>\n      <td>0.066709</td>\n      <td>0.368587</td>\n      <td>1.323611</td>\n      <td>...</td>\n      <td>1.439100</td>\n      <td>1.203172</td>\n      <td>0.787512</td>\n      <td>0.178735</td>\n      <td>0.667279</td>\n      <td>0.644420</td>\n      <td>1.120357</td>\n      <td>1.260047</td>\n      <td>0.071751</td>\n      <td>1.355075</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_4991.jpg</th>\n      <td>120</td>\n      <td>0.068341</td>\n      <td>0.824908</td>\n      <td>0.193437</td>\n      <td>0.906468</td>\n      <td>2.191380</td>\n      <td>0.567653</td>\n      <td>2.182863</td>\n      <td>0.541500</td>\n      <td>0.469749</td>\n      <td>...</td>\n      <td>0.270837</td>\n      <td>0.148257</td>\n      <td>0.538312</td>\n      <td>0.221652</td>\n      <td>1.261061</td>\n      <td>0.393819</td>\n      <td>0.931265</td>\n      <td>1.368547</td>\n      <td>0.725584</td>\n      <td>1.802775</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_3024.jpg</th>\n      <td>120</td>\n      <td>0.012424</td>\n      <td>0.074204</td>\n      <td>1.992666</td>\n      <td>0.076113</td>\n      <td>0.573071</td>\n      <td>1.246892</td>\n      <td>0.586113</td>\n      <td>0.114273</td>\n      <td>1.963169</td>\n      <td>...</td>\n      <td>0.544384</td>\n      <td>0.052004</td>\n      <td>0.279680</td>\n      <td>0.214920</td>\n      <td>1.575158</td>\n      <td>1.586292</td>\n      <td>1.686255</td>\n      <td>0.970767</td>\n      <td>1.198236</td>\n      <td>0.281134</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_3635.jpg</th>\n      <td>120</td>\n      <td>0.090567</td>\n      <td>0.394184</td>\n      <td>1.207222</td>\n      <td>0.123069</td>\n      <td>2.618800</td>\n      <td>0.823760</td>\n      <td>3.099759</td>\n      <td>0.373843</td>\n      <td>0.408895</td>\n      <td>...</td>\n      <td>0.082895</td>\n      <td>0.005232</td>\n      <td>0.012785</td>\n      <td>0.310990</td>\n      <td>0.028843</td>\n      <td>1.175330</td>\n      <td>0.576579</td>\n      <td>1.986010</td>\n      <td>0.086537</td>\n      <td>0.805687</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_2988.jpg</th>\n      <td>120</td>\n      <td>0.249121</td>\n      <td>0.176359</td>\n      <td>2.857338</td>\n      <td>0.408916</td>\n      <td>0.582186</td>\n      <td>1.393884</td>\n      <td>2.366030</td>\n      <td>0.707135</td>\n      <td>0.630027</td>\n      <td>...</td>\n      <td>0.592481</td>\n      <td>0.396963</td>\n      <td>0.142146</td>\n      <td>0.550736</td>\n      <td>0.031739</td>\n      <td>0.102475</td>\n      <td>2.250938</td>\n      <td>0.885802</td>\n      <td>1.031099</td>\n      <td>0.105213</td>\n    </tr>\n    <tr>\n      <th>n02116738-African_hunting_dog\\n02116738_6330.jpg</th>\n      <td>120</td>\n      <td>0.006490</td>\n      <td>0.197918</td>\n      <td>0.512689</td>\n      <td>0.059964</td>\n      <td>0.486442</td>\n      <td>0.658949</td>\n      <td>3.135226</td>\n      <td>1.372569</td>\n      <td>0.247659</td>\n      <td>...</td>\n      <td>0.280469</td>\n      <td>0.263225</td>\n      <td>0.788225</td>\n      <td>1.298100</td>\n      <td>0.071682</td>\n      <td>0.007359</td>\n      <td>1.349891</td>\n      <td>2.497369</td>\n      <td>0.263831</td>\n      <td>0.009741</td>\n    </tr>\n  </tbody>\n</table>\n<p>8580 rows × 513 columns</p>\n</div>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = reformat_df(df_test)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zFDJR22HLJn",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Create train/validation/test splits**\n",
    "* From the training set, we will create a small validation set which is going to be used to find the best Hyperparameter for the models.\n",
    "* We cant use the test set because that will lead to something called model leakage!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:37.146046Z",
     "iopub.status.busy": "2024-04-26T06:54:37.145656Z",
     "iopub.status.idle": "2024-04-26T06:54:37.256208Z",
     "shell.execute_reply": "2024-04-26T06:54:37.255187Z",
     "shell.execute_reply.started": "2024-04-26T06:54:37.146013Z"
    },
    "id": "-vxJCpUGH7aD",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:50.134121Z",
     "start_time": "2024-04-27T03:27:50.070677Z"
    }
   },
   "outputs": [],
   "source": [
    "# train features\n",
    "X = df_train.iloc[:,1:]\n",
    "# train labels\n",
    "y = df_train.iloc[:,0]\n",
    "\n",
    "# create the training & validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,test_size=0.15, shuffle=True, random_state=7)\n",
    "\n",
    "# re-assign the test set variables for consistency & shuffle\n",
    "df_test = df_test.sample(frac = 1)\n",
    "X_test = df_test.iloc[:,1:]\n",
    "y_test = df_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:39.583879Z",
     "iopub.status.busy": "2024-04-26T06:54:39.583510Z",
     "iopub.status.idle": "2024-04-26T06:54:39.590689Z",
     "shell.execute_reply": "2024-04-26T06:54:39.589093Z",
     "shell.execute_reply.started": "2024-04-26T06:54:39.583851Z"
    },
    "id": "WDZJLrxssRPW",
    "outputId": "a3dfd577-edd9-4378-f266-7fa2df75f78b",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:50.134765Z",
     "start_time": "2024-04-27T03:27:50.104621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (10200, 512)\n",
      "Training Labels: (10200,)\n",
      "Validation Data: (1800, 512)\n",
      "Validation Labels: (1800,)\n",
      "Testing Data: (8580, 512)\n",
      "Testing Labels: (8580,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data: {X_train.shape}\")\n",
    "print(f\"Training Labels: {y_train.shape}\")\n",
    "\n",
    "print(f\"Validation Data: {X_valid.shape}\")\n",
    "print(f\"Validation Labels: {y_valid.shape}\")\n",
    "\n",
    "print(f\"Testing Data: {X_test.shape}\")\n",
    "print(f\"Testing Labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQSbshQXnNxD",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Preprocessing**\n",
    "* Training & Validation datasets will be Normalised\n",
    "* Most ML models expect the class values to start from zero to n. Our targets start from one to n, hence we need to fix this up.\n",
    "* PCA will be used to create a secondary dataset which you will use to experiment to see if reducing the attributes will lead to better classification results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AT067_t4nTdk"
   },
   "source": [
    "## ** 1)Normalize values**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:42.529630Z",
     "iopub.status.busy": "2024-04-26T06:54:42.529140Z",
     "iopub.status.idle": "2024-04-26T06:54:42.649581Z",
     "shell.execute_reply": "2024-04-26T06:54:42.648441Z",
     "shell.execute_reply.started": "2024-04-26T06:54:42.529588Z"
    },
    "id": "CqijNMgutrPe",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:50.153333Z",
     "start_time": "2024-04-27T03:27:50.108973Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the StandardScaler\n",
    "stdsclr = StandardScaler()\n",
    "# fit it to the trainset ONLY\n",
    "stdsclr.fit(X_train)\n",
    "# Apply it to Train data\n",
    "X_train_sclr = stdsclr.transform(X_train)\n",
    "# Apply it to Valid data\n",
    "X_valid_sclr = stdsclr.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:45.207047Z",
     "iopub.status.busy": "2024-04-26T06:54:45.206671Z",
     "iopub.status.idle": "2024-04-26T06:54:45.212403Z",
     "shell.execute_reply": "2024-04-26T06:54:45.211441Z",
     "shell.execute_reply.started": "2024-04-26T06:54:45.207019Z"
    },
    "id": "2nnPAPkmuNQe",
    "outputId": "fa33bfc7-aa3e-41bc-bd06-f06eff3a42f6",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:50.171585Z",
     "start_time": "2024-04-27T03:27:50.137586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Scaled: (10200, 512)\n",
      "Validation Data Scaled: (1800, 512)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Data Scaled: {X_train_sclr.shape}\")\n",
    "print(f\"Validation Data Scaled: {X_valid_sclr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSpK3Or0voCO"
   },
   "source": [
    "## **2) Rebase target classes**\n",
    "* subtract 1 from all target labels to shift the range from 0 to 119 instead of 1 to 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:48.574630Z",
     "iopub.status.busy": "2024-04-26T06:54:48.574255Z",
     "iopub.status.idle": "2024-04-26T06:54:48.581165Z",
     "shell.execute_reply": "2024-04-26T06:54:48.579962Z",
     "shell.execute_reply.started": "2024-04-26T06:54:48.574601Z"
    },
    "id": "234yxZrFvni6",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:50.213296Z",
     "start_time": "2024-04-27T03:27:50.142163Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = y_train - 1\n",
    "y_valid = y_valid - 1\n",
    "y_test = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:53.830059Z",
     "iopub.status.busy": "2024-04-26T06:54:53.829718Z",
     "iopub.status.idle": "2024-04-26T06:54:53.848108Z",
     "shell.execute_reply": "2024-04-26T06:54:53.847273Z",
     "shell.execute_reply.started": "2024-04-26T06:54:53.830032Z"
    },
    "id": "O0vmD-2NwM88",
    "outputId": "0cc7930b-062c-47e6-f28b-ece6694e1e61",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:50.214038Z",
     "start_time": "2024-04-27T03:27:50.144723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "target\n0      84\n1      84\n2      93\n3      89\n4      90\n       ..\n115    84\n116    85\n117    86\n118    82\n119    79\nName: count, Length: 120, dtype: int64"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsefUcd9naQh"
   },
   "source": [
    "## **3) PCA**\n",
    "* A secondary dataset used for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-26T06:55:09.539676Z",
     "iopub.status.busy": "2024-04-26T06:55:09.539298Z",
     "iopub.status.idle": "2024-04-26T06:55:10.446878Z",
     "shell.execute_reply": "2024-04-26T06:55:10.445633Z",
     "shell.execute_reply.started": "2024-04-26T06:55:09.539647Z"
    },
    "id": "Zsw4XtT6nZmJ",
    "outputId": "e84a5795-3505-4c1c-8aa5-588e3e87e302",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:53.075738Z",
     "start_time": "2024-04-27T03:27:50.149284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed training set shape: (10200, 256)\n",
      "Transformed validation set shape: (1800, 256)\n",
      "Transformed test set shape: (8580, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomkwok/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create PCA to keep 95% of the variance\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# Fit PCA on the training dataset\n",
    "pca.fit(X_train_sclr)\n",
    "\n",
    "# Transform the training, validation, and test datasets\n",
    "X_train_pca = pca.transform(X_train_sclr)\n",
    "X_valid_pca = pca.transform(X_valid_sclr)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Output the results\n",
    "print(\"Transformed training set shape:\", X_train_pca.shape)\n",
    "print(\"Transformed validation set shape:\", X_valid_pca.shape)\n",
    "print(\"Transformed test set shape:\", X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lC25lGNQnTCq",
    "outputId": "dc6923cd-be0f-4493-defc-1dee728ab33e",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:53.081746Z",
     "start_time": "2024-04-27T03:27:53.074196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data PCA: (10200, 256)\n",
      "Training Labels: (10200,)\n",
      "Validation Data PCA: (1800, 256)\n",
      "Validation Labels: (1800,)\n",
      "Testing Data PCA: (8580, 256)\n",
      "Testing Labels: (8580,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data PCA: {X_train_pca.shape}\")\n",
    "print(f\"Training Labels: {y_train.shape}\")\n",
    "\n",
    "print(f\"Validation Data PCA: {X_valid_pca.shape}\")\n",
    "print(f\"Validation Labels: {y_valid.shape}\")\n",
    "\n",
    "print(f\"Testing Data PCA: {X_test_pca.shape}\")\n",
    "print(f\"Testing Labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exHhaRw5yC_c",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Display Data Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qh-06QkryjVU"
   },
   "source": [
    "## **Dataset 1 - all features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqCuyStuyLFl",
    "outputId": "899e7de2-952a-4984-ab8a-646ac69940e1",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:53.120384Z",
     "start_time": "2024-04-27T03:27:53.082199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "image_path\nn02102177-Welsh_springer_spaniel\\n02102177_922.jpg     67\nn02091032-Italian_greyhound\\n02091032_9592.jpg         20\nn02108000-EntleBucher\\n02108000_1256.jpg               90\nn02108000-EntleBucher\\n02108000_3682.jpg               90\nn02108915-French_bulldog\\n02108915_6270.jpg            94\n                                                     ... \nn02110958-pug\\n02110958_4993.jpg                      102\nn02090721-Irish_wolfhound\\n02090721_2860.jpg           19\nn02100735-English_setter\\n02100735_2065.jpg            61\nn02109525-Saint_Bernard\\n02109525_5007.jpg             96\nn02111129-Leonberg\\n02111129_3573.jpg                 103\nName: target, Length: 8580, dtype: int64"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "X_train_sclr\n",
    "y_train\n",
    "# validation\n",
    "X_valid_sclr\n",
    "y_valid\n",
    "# test\n",
    "X_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ijfe-IBGyqM7"
   },
   "source": [
    "## **Dataset 2 - PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVsiEfUTyQat",
    "outputId": "3d3ab36a-f700-4395-b174-e044dddd72aa",
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:53.121688Z",
     "start_time": "2024-04-27T03:27:53.091395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "image_path\nn02102177-Welsh_springer_spaniel\\n02102177_922.jpg     67\nn02091032-Italian_greyhound\\n02091032_9592.jpg         20\nn02108000-EntleBucher\\n02108000_1256.jpg               90\nn02108000-EntleBucher\\n02108000_3682.jpg               90\nn02108915-French_bulldog\\n02108915_6270.jpg            94\n                                                     ... \nn02110958-pug\\n02110958_4993.jpg                      102\nn02090721-Irish_wolfhound\\n02090721_2860.jpg           19\nn02100735-English_setter\\n02100735_2065.jpg            61\nn02109525-Saint_Bernard\\n02109525_5007.jpg             96\nn02111129-Leonberg\\n02111129_3573.jpg                 103\nName: target, Length: 8580, dtype: int64"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset 2 - PCA\n",
    "# train\n",
    "X_train_pca\n",
    "y_train\n",
    "# validation\n",
    "X_valid_pca\n",
    "y_valid\n",
    "# test\n",
    "X_test_pca\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2PHxcWbzE9s"
   },
   "source": [
    "# **Model 3: Multi-layer Perceptron (MLP)**\n",
    "\n",
    "There are two models that will be trained:\n",
    "## Model 1: \n",
    "* 4 layers\n",
    "* 512, 256, 128, 120 neurons\n",
    "* with ReLU activation function and Softmax activation function\n",
    "\n",
    "## Model 2:\n",
    "* 4 layers\n",
    "* 512, 1024, 512, 120 neurons\n",
    "* with ReLU activation function and Softmax activation function\n",
    "* a dropout layer to prevent overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# %pip install torch\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check PyTorch version and Apple Silicon support\n",
    "print(torch.__version__)\n",
    "# Is MPS even available? macOS 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "# Was the current version of PyTorch built with MPS activated?\n",
    "print(torch.backends.mps.is_built())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T03:27:53.122345Z",
     "start_time": "2024-04-27T03:27:53.100489Z"
    }
   },
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the MLP model class (OG)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512 * 2, 256)  # Increase the number of neurons\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 120)\n",
    "        self.relu = nn.ReLU()   # ReLU activation function to introduce non-linearity in the model\n",
    "        self.softmax = nn.Softmax(dim=1)    # Softmax activation function to convert the output to probabilities\n",
    "\n",
    "    def forward(self, x): # Forward pass\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T05:49:12.360427Z",
     "start_time": "2024-04-27T05:49:12.350010Z"
    }
   },
   "execution_count": 197
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP2, self).__init__()\n",
    "        self.fc1 = nn.Linear(int(input_size), int(input_size))\n",
    "        self.fc2 = nn.Linear(int(input_size), int(input_size * 2))\n",
    "        self.fc3 = nn.Linear(int(input_size * 2), int(input_size)) \n",
    "        self.fc4 = nn.Linear(int(input_size), int(input_size / 2))\n",
    "        self.fc5 = nn.Linear(int(input_size / 2), 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout layer\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        nn.init.xavier_uniform_(self.fc4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T06:05:37.820676Z",
     "start_time": "2024-04-27T06:05:37.758756Z"
    }
   },
   "execution_count": 226
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(model, loader, num_epoch):\n",
    "    shape = loader.dataset.tensors[0].shape[1]\n",
    "    print(f\"Input shape: {shape}\")\n",
    "    \n",
    "    # Create an instance of the model, and define the loss function and optimizer\n",
    "    if model == 1:\n",
    "        model = MLP(shape)\n",
    "    elif model == 2:\n",
    "        model = MLP2(shape)\n",
    "    print(model)\n",
    "    \n",
    "    # Initialize the loss values\n",
    "    criterion = nn.CrossEntropyLoss() # Loss function: Cross-entropy loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)  # Add weight decay for L2 regularization\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)  # Add learning rate decay\n",
    "    \n",
    "    for epoch in range(num_epoch): # 10 epochs\n",
    "        for i, (inputs, labels) in enumerate(loader):\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, labels) # Compute the loss\n",
    "    \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save the loss and accuracy value\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "        \n",
    "        # Save the accuracy value\n",
    "        correct_predictions = (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        total_predictions = labels.size(0)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        accuracy_values.append(accuracy)\n",
    "\n",
    "    # Save the model\n",
    "    model_name = f\"model{model}.pt\"\n",
    "    torch.save(model.state_dict(), model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T06:05:38.393142Z",
     "start_time": "2024-04-27T06:05:38.388081Z"
    }
   },
   "execution_count": 227
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "def plot_loss_accuracy(loss_values, accuracy_values):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color=color)\n",
    "    ax1.plot(loss_values, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Accuracy', color=color)\n",
    "    ax2.plot(accuracy_values, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T06:05:39.729067Z",
     "start_time": "2024-04-27T06:05:39.722854Z"
    }
   },
   "execution_count": 228
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kt/y0r0pcx938l9pnmjlxpbm8zm0000gn/T/ipykernel_78017/2146905193.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_tensor = torch.tensor(y_train)\n",
      "/var/folders/kt/y0r0pcx938l9pnmjlxpbm8zm0000gn/T/ipykernel_78017/2146905193.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_valid_tensor = torch.tensor(y_valid)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for MLP\n",
    "# Convert the data to tensors for training\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "y_valid_tensor = torch.tensor(y_valid)\n",
    "\n",
    "# PCA\n",
    "## Training\n",
    "X_train_tensor_pca = torch.tensor(X_train_pca)\n",
    "train_data_pca = TensorDataset(X_train_tensor_pca, y_train_tensor)\n",
    "train_loader_pca = DataLoader(train_data_pca)\n",
    "## Validation\n",
    "valid_data_pca = TensorDataset(torch.tensor(X_valid_pca), y_valid_tensor)\n",
    "valid_loader_pca = DataLoader(valid_data_pca)\n",
    "\n",
    "# All features\n",
    "## Training\n",
    "X_train_tensor = torch.tensor(X_train_sclr)\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data)\n",
    "# Validation\n",
    "valid_data = TensorDataset(torch.tensor(X_valid_sclr), y_valid_tensor)\n",
    "valid_loader = DataLoader(valid_data)\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T06:06:06.601422Z",
     "start_time": "2024-04-27T06:06:06.531526Z"
    }
   },
   "execution_count": 229
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T06:07:08.115922Z",
     "start_time": "2024-04-27T06:06:09.077835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: 256\n",
      "MLP2(\n",
      "  (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc5): Linear(in_features=128, out_features=120, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Epoch 1, Loss: 4.787493705749512\n",
      "Accuracy: 0.0\n",
      "Epoch 2, Loss: 4.787498474121094\n",
      "Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[230], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader_pca\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Visualize the loss values\u001B[39;00m\n\u001B[1;32m      4\u001B[0m plot_loss_accuracy(loss_values, accuracy_values)\n",
      "Cell \u001B[0;32mIn[227], line 29\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, loader, num_epoch)\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n\u001B[1;32m     28\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 29\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Update the weights\u001B[39;00m\n\u001B[1;32m     31\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Save the loss and accuracy value\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     73\u001B[0m instance\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     74\u001B[0m wrapped \u001B[38;5;241m=\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance, \u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m             )\n\u001B[0;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/adam.py:166\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    155\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    157\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    158\u001B[0m         group,\n\u001B[1;32m    159\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    163\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    164\u001B[0m         state_steps)\n\u001B[0;32m--> 166\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/adam.py:316\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    314\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 316\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m     \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/adam.py:391\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    388\u001B[0m     param \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mview_as_real(param)\n\u001B[1;32m    390\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[0;32m--> 391\u001B[0m \u001B[43mexp_avg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlerp_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    392\u001B[0m exp_avg_sq\u001B[38;5;241m.\u001B[39mmul_(beta2)\u001B[38;5;241m.\u001B[39maddcmul_(grad, grad\u001B[38;5;241m.\u001B[39mconj(), value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta2)\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m capturable \u001B[38;5;129;01mor\u001B[39;00m differentiable:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(2, train_loader_pca, 20)\n",
    "# Visualize the loss values\n",
    "plot_loss_accuracy(loss_values, accuracy_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T06:02:24.805634Z",
     "start_time": "2024-04-27T06:01:12.727678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: 512\n",
      "MLP2(\n",
      "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Epoch 1, Loss: 4.787476539611816\n",
      "Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[225], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Visualize the loss values\u001B[39;00m\n\u001B[1;32m      4\u001B[0m plot_loss_accuracy(loss_values, accuracy_values)\n",
      "Cell \u001B[0;32mIn[221], line 29\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, loader, num_epoch)\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n\u001B[1;32m     28\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 29\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Update the weights\u001B[39;00m\n\u001B[1;32m     31\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Save the loss and accuracy value\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     73\u001B[0m instance\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     74\u001B[0m wrapped \u001B[38;5;241m=\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance, \u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m             )\n\u001B[0;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/adam.py:166\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    155\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    157\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    158\u001B[0m         group,\n\u001B[1;32m    159\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    163\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    164\u001B[0m         state_steps)\n\u001B[0;32m--> 166\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/adam.py:316\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    314\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 316\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m     \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/torch/optim/adam.py:380\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    377\u001B[0m step_t \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight_decay \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 380\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[43mgrad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(param):\n\u001B[1;32m    383\u001B[0m     grad \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mview_as_real(grad)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(2, train_loader, 20)\n",
    "# Visualize the loss values\n",
    "plot_loss_accuracy(loss_values, accuracy_values)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4883285,
     "sourceId": 8233788,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
