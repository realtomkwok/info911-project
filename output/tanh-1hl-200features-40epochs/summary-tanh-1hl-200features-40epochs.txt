Model Summary:
MLP_1HL(
  (fc1): Linear(in_features=200, out_features=360, bias=True)
  (tanh): Tanh()
  (dropout): Dropout(p=0.5, inplace=False)
  (fc2): Linear(in_features=360, out_features=120, bias=True)
)

Loss function:
CrossEntropyLoss()

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 1.4780882941434607e-05
    maximize: False
    weight_decay: 0.01
)

Learning Rate Scheduler:
<torch.optim.lr_scheduler.ExponentialLR object at 0x2e89a2190>

Number of Epochs: 40

Final Training Loss: 0.7851731181144714
Final Validation Loss: 1.103606663883006

Average Validation Loss: 1.1966941784395693

F1 Score: 0.7531860292112876

Confusion Matrix:
[[ 8  0  0 ...  0  0  0]
 [ 0 14  0 ...  0  0  0]
 [ 0  0  7 ...  0  0  0]
 ...
 [ 0  0  0 ... 12  0  0]
 [ 0  0  0 ...  2 16  0]
 [ 0  0  0 ...  0  0 21]]

Total Training Time: 6.0 minutes, 12.26 seconds. That is 372.26 seconds.